"""Strategy v1.0 Skeleton

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qk0_qcTIt9TBBEXisPDphYJJQ6b54s2M
"""

"""
Strategy v1.0 Backtest Skeleton
- Universe: SPY, EFA, EEM, TLT, IEF, GLD
- Signal: 12-month (252 trading days) total return > 0 => long, else flat
- Vol: 60-day realized vol (annualized)
- Rebalance: monthly (end-of-month -> next trading day close-to-close returns)
- Position sizing: inverse vol across active signals + normalization
- Costs: 5 bps per 1.0 turnover (applied on rebalance days)
"""


import numpy as np
import pandas as pd

# Optional: data source
# pip install yfinance
import yfinance as yf


# ----------------------------
# Config
# ----------------------------
TICKERS = ["SPY", "EFA", "EEM", "TLT", "IEF", "GLD"]

LOOKBACK_MOM = 252          # 12 months approx
LOOKBACK_VOL = 60           # 60 trading days
TARGET_PORT_VOL = 0.10      # 10% annualized
MAX_WEIGHT = 0.30           # 30% cap per asset
TCOST_BPS = 5               # 5 bps per turnover unit

START_DATE = "2004-01-01"
END_DATE = None             # None => today


# ----------------------------
# Helpers
# ----------------------------
def download_adj_close(tickers: list[str], start: str, end: str | None) -> pd.DataFrame:
    frames = []
    for t in tickers:
        df = yf.download(t, start=start, end=end, auto_adjust=True, progress=False)
        if df.empty:
            raise RuntimeError(f"No data downloaded for {t}")
        frames.append(df["Close"].rename(t.upper()))
    px = pd.concat(frames, axis=1).dropna(how="all")
    px = px.ffill().dropna()
    return px



def quarter_end_rebalance_dates(index: pd.DatetimeIndex) -> pd.DatetimeIndex:
    # Quarter-end calendar dates
    q_ends = pd.Series(index=index, data=1).resample("QE").last().index

    # Align to nearest previous trading day in index
    aligned = []
    for d in q_ends:
        if d in index:
            aligned.append(d)
        else:
            prev = index[index.get_indexer([d], method="ffill")[0]]
            aligned.append(prev)
    return pd.DatetimeIndex(sorted(set(aligned)))



def annualized_vol(returns: pd.DataFrame, window: int) -> pd.DataFrame:
    return returns.rolling(window).std() * np.sqrt(252)

def compute_signal(prices: pd.DataFrame, lookback: int = 252) -> pd.DataFrame:
    """
    Plain 12M momentum:
    signal_t = 1 if (price_{t-1} / price_{t-1-lookback} - 1) > 0 else 0
    """
    pr = prices.shift(1)
    mom = pr / pr.shift(lookback) - 1.0
    sig = (mom > 0).astype(float)
    return sig

def compute_signal_12_1(prices: pd.DataFrame, lookback: int = 252, skip: int = 21) -> pd.DataFrame:
    """
    12–1 momentum signal:
    compares price at (t-1-skip) vs price at (t-1-skip-lookback)
    signal_t = 1 if that return > 0 else 0
    """
    pr = prices.shift(1 + skip)
    mom = pr / pr.shift(lookback) - 1.0
    sig = (mom > 0).astype(float)
    return sig

def compute_signal_6_12(prices: pd.DataFrame,
                        lb_short: int = 126,
                        lb_long: int = 252) -> pd.DataFrame:
    """
    Combined 6M + 12M momentum signal.
    signal_t = 1 if average of (6M return, 12M return) > 0 else 0
    """
    pr = prices.shift(1)

    mom_6 = pr / pr.shift(lb_short) - 1.0
    mom_12 = pr / pr.shift(lb_long) - 1.0

    mom_avg = 0.5 * (mom_6 + mom_12)
    sig = (mom_avg > 0).astype(float)

    return sig

def compute_risk_on_filter(prices: pd.DataFrame, benchmark: str = "SPY", ma_window: int = 200) -> pd.Series:
    """
    Risk-on filter: benchmark price > its moving average.
    Returns a Series indexed like prices.index with 1.0 (risk-on) or 0.0 (risk-off).
    """
    bench = prices[benchmark].copy()
    ma = bench.rolling(ma_window).mean()
    risk_on = (bench > ma).astype(float)
    return risk_on



def cap_and_renormalize(weights: pd.Series, max_w: float) -> pd.Series:
    """
    Caps weights at max_w and re-normalizes remaining proportionally to keep sum(abs)=1 (if possible).
    Assumes non-negative weights (long/flat).
    """
    w = weights.copy()
    if w.abs().sum() == 0:
        return w

    # First normalize so sum=1 for active legs
    w = w / w.sum()

    # Iteratively cap and redistribute excess
    for _ in range(10):
        over = w > max_w
        if not over.any():
            break

        excess = (w[over] - max_w).sum()
        w[over] = max_w

        under = ~over
        if under.any() and excess > 0:
            w[under] += excess * (w[under] / w[under].sum())
        else:
            # If everything is capped, we’re done
            break

    # Final normalize (guard against numeric issues)
    if w.sum() > 0:
        w = w / w.sum()

    return w


# ----------------------------
# Backtest
# ----------------------------
def run_backtest(prices: pd.DataFrame) -> dict[str, pd.DataFrame | pd.Series]:
    prices = prices.copy()
    rets = prices.pct_change().dropna()

    # Compute inputs
    sig = compute_signal(prices, LOOKBACK_MOM)   # plain 12M momentum
    risk_on = compute_risk_on_filter(prices, benchmark="SPY", ma_window=200)
    vol = annualized_vol(rets, LOOKBACK_VOL)              # annualized vol

    # Determine rebalance dates
    rb_dates = quarter_end_rebalance_dates(rets.index)

    # Weights dataframe (daily). We'll set weights on rebalance dates and carry forward.
    w = pd.DataFrame(index=rets.index, columns=rets.columns, data=0.0)

    prev_w = pd.Series(index=rets.columns, data=0.0)

    for d in rb_dates:
        if d not in w.index:
            continue

        # Eligible data at date d
        s = sig.loc[d].fillna(0.0) * float(risk_on.loc[d])
        v = vol.loc[d].replace(0, np.nan)

        # Raw inverse-vol weights for active signals
        raw = (s / v).replace([np.inf, -np.inf], np.nan).fillna(0.0)

        if raw.sum() == 0:
            new_w = pd.Series(index=rets.columns, data=0.0)
        else:
            # 1) Normalize inverse-vol weights across active signals (long-only)
            new_w = raw / raw.sum()

            # 2) Vol target at portfolio level using recent covariance
            cov = rets.loc[:d].tail(LOOKBACK_VOL).cov() * 252
            port_var = float(new_w.values @ cov.values @ new_w.values)
            port_vol = np.sqrt(port_var) if port_var > 0 else np.nan

            if np.isfinite(port_vol) and port_vol > 0:
                scale = TARGET_PORT_VOL / port_vol
                new_w = new_w * scale

            # 3) HARD CAP AFTER scaling (this prevents >30% positions)
            new_w = new_w.clip(lower=0.0, upper=MAX_WEIGHT)

            # 4) Do NOT renormalize after capping -> leftover goes to cash


        # Set weights on rebalance day (effective starting next day’s return)
        w.loc[d] = new_w
        prev_w = new_w

    # Carry weights forward daily
    w = w.ffill().fillna(0.0)

    # Compute turnover on rebalance days for costs:
    # turnover_t = sum(|w_t - w_{t-1}|)  (one-way)
    dw = w.diff().abs().sum(axis=1).fillna(0.0)
    dw.loc[~dw.index.isin(rb_dates)] = 0.0



    # Strategy gross daily returns
    strat_gross = (w.shift(1) * rets).sum(axis=1)  # weights decided at t-1 applied to return at t

    # Apply transaction costs on days AFTER rebalance weight changes take effect
    # Using dw at day t as change in weights set at t, affecting trading around t close
    # Conservative: apply cost on the same day as weight change is recorded.
    tcost = (TCOST_BPS / 10000.0) * dw
    strat_net = strat_gross - tcost

    # Equity curves
    eq_gross = (1 + strat_gross).cumprod()
    eq_net = (1 + strat_net).cumprod()

    results = {
        "returns": rets,
        "signal": sig,
        "vol": vol,
        "weights": w,
        "turnover": dw,
        "strat_gross": strat_gross,
        "strat_net": strat_net,
        "eq_gross": eq_gross,
        "eq_net": eq_net,
    }
    return results


# ----------------------------
# Stats
# ----------------------------
def perf_stats(daily_ret: pd.Series) -> pd.Series:
    daily_ret = daily_ret.dropna()
    if daily_ret.empty:
        return pd.Series(dtype=float)

    ann_ret = (1 + daily_ret).prod() ** (252 / len(daily_ret)) - 1
    ann_vol = daily_ret.std() * np.sqrt(252)
    sharpe = ann_ret / ann_vol if ann_vol > 0 else np.nan

    eq = (1 + daily_ret).cumprod()
    peak = eq.cummax()
    dd = (eq / peak) - 1
    max_dd = dd.min()

    hit_rate = (daily_ret > 0).mean()

    return pd.Series({
        "Ann Return (CAGR)": ann_ret,
        "Ann Vol": ann_vol,
        "Sharpe": sharpe,
        "Max Drawdown": max_dd,
        "Hit Rate (daily)": hit_rate,
    })


# ----------------------------
# Run
# ----------------------------
if __name__ == "__main__":
    prices = download_adj_close(TICKERS, START_DATE, END_DATE)
    bt = run_backtest(prices)
    save_results_plots(bt, out_dir="results")


    print("Gross stats")
    print(perf_stats(bt["strat_gross"]).round(4))
    print("\nNet stats")
    print(perf_stats(bt["strat_net"]).round(4))

    # Optional quick sanity checks
    print("\nAverage turnover:", bt["turnover"].mean().round(4))
    print("Max single-asset weight:", round(float(bt["weights"].abs().max().max()), 4))

import os
import matplotlib.pyplot as plt

def save_results_plots(bt: dict, out_dir: str = "results") -> None:
    os.makedirs(out_dir, exist_ok=True)

    eq = bt["eq_net"].dropna()
    # Equity curve
    plt.figure()
    plt.plot(eq.index, eq.values)
    plt.title("Equity Curve (Net)")
    plt.xlabel("Date")
    plt.ylabel("Growth of $1")
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "equity_curve.png"), dpi=200)
    plt.close()

    # Drawdown curve
    running_max = eq.cummax()
    dd = (eq / running_max) - 1.0

    plt.figure()
    plt.plot(dd.index, dd.values)
    plt.title("Drawdown (Net)")
    plt.xlabel("Date")
    plt.ylabel("Drawdown")
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, "drawdown.png"), dpi=200)
    plt.close()


"""***v1.0 Production Baseline***

Gross stats
*   Ann Return (CAGR)    0.0097
*   Ann Vol              0.0114
*   Sharpe               0.8502
*   Max Drawdown        -0.0147
*   Hit Rate (daily)     0.0092

Net stats
*   Ann Return (CAGR)    0.0080
*   Ann Vol              0.0115
*   Sharpe               0.6994
*   Max Drawdown        -0.0163
*   Hit Rate (daily)     0.0092

*   Average turnover: 0.0133
*   Max single-asset weight: 0.3
"""
